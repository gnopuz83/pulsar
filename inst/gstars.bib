@article{Mazumder2012,
abstract = {We consider the sparse inverse covariance regularization problem or graphical lasso with regularization parameter $\lambda$. Suppose the sample covariance graph formed by thresholding the entries of the sample covariance matrix at $\lambda$ is decomposed into connected components. We show that the vertex-partition induced by the connected components of the thresholded sample covariance graph (at $\lambda$) is exactly equal to that induced by the connected components of the estimated concentration graph, obtained by solving the graphical lasso problem for the same $\lambda$. This characterizes a very interesting property of a path of graphical lasso solutions. Furthermore, this simple rule, when used as a wrapper around existing algorithms for the graphical lasso, leads to enormous performance gains. For a range of values of $\lambda$, our proposal splits a large graphical lasso problem into smaller tractable problems, making it possible to solve an otherwise infeasible large-scale problem. We illustrate the graceful scalability of our proposal via synthetic and real-life microarray examples.},
archivePrefix = {arXiv},
arxivId = {1108.3829},
author = {Mazumder, Rahul and Hastie, Trevor},
doi = {arXiv:1108.3829},
eprint = {1108.3829},
isbn = {1532-4435 (Print) 1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {concentration graph,els,gaussian graphical mod-,graph connected components,graphical lasso,large scale covariance estimation,sparse inverse covariance selection,sparsity},
pages = {781--794},
pmid = {25392704},
title = {{Exact covariance thresholding into connected components for large-scale Graphical Lasso}},
url = {https://arxiv.org/abs/1108.3829$\backslash$nhttp://jmlr.org/papers/v13/mazumder12a.html},
volume = {13},
year = {2012}
}
@article{Lange2004,
abstract = {Data clustering describes a set of frequently employed techniques in exploratory data analysis to extract "natural" group structure in data. Such groupings need to be validated to separate the signal in the data from spurious structure. In this context, finding an appropriate number of clusters is a particularly important model selection question. We introduce a measure of cluster stability to assess the validity of a cluster model. This stability measure quantifies the reproducibility of clustering solutions on a second sample, and it can be interpreted as a classification risk with regard to class labels produced by a clustering algorithm. The preferred number of clusters is determined by minimizing this classification risk as a function of the number of clusters. Convincing results are achieved on simulated as well as gene expression data sets. Comparisons to other methods demonstrate the competitive performance of our method and its suitability as a general validation tool for clustering solutions in real-world problems.},
author = {Lange, Tilman and Roth, Volker and Braun, Mikio L and Buhmann, Joachim M},
doi = {10.1162/089976604773717621},
file = {:Users/cmueller/Documents/Mendeley Desktop/Lange et al. - 2004 - Stability-based validation of clustering solutions.pdf:pdf},
isbn = {0899-7667 (Print)},
issn = {0899-7667},
journal = {Neural computation},
number = {6},
pages = {1299--1323},
pmid = {15130251},
title = {{Stability-based validation of clustering solutions.}},
volume = {16},
year = {2004}
}
@article{Wang1993,
author = {Wang, Y. H.},
file = {:Users/cmueller/Documents/Mendeley Desktop/Wang - 1993 - On the number of successes in independent trials.pdf:pdf},
journal = {Statistica Sinica},
pages = {295--312},
title = {{On the number of successes in independent trials}},
volume = {3},
year = {1993}
}
@article{Katti1962,
author = {Katti, S. K. and Gurland, John},
file = {:Users/cmueller/Documents/Mendeley Desktop/Katti, Gurland - 1962 - Some Methods of Estimation for the Poisson Binomial Distribution.pdf:pdf},
journal = {Biometrics},
number = {1},
pages = {42--51},
title = {{Some Methods of Estimation for the Poisson Binomial Distribution}},
url = {http://www.jstor.org/stable/2527709},
volume = {18},
year = {1962}
}
@article{Chen1997,
abstract = {The distribution of Z1+···+ZN is called Poisson-Binomial if the Zi are independent Bernoulli random variables with not-all-equal probabilities of success. It is noted that such a distribution and its computation play an important role in a number of seemingly unrelated research areas such as survey sampling, case-control studies, and survival analysis. In this article, we provide a general theory about the Poisson-Binomial distribution concerning its computation and applications, and as by-products, we propose new weighted sampling schemes for finite population, a new method for hypothesis testing in logistic regression, and a new algorithm for finding the maximum conditional likelihood estimate (MCLE) in case-control studies. Two of our weighted sampling schemes are direct generalizations of the “sequential” and “reservoir” methods of Fan, Muller and Rezucha (1962) for simple random sampling, which are of interest to computer scientists. Our new algorithm for finding the MCLE in case-control studies is an iterative weighted least squares method, which naturally bridges prospective and retrospective GLMs.},
author = {Chen, Sean X and Liu, Jun S},
file = {:Users/cmueller/Documents/Mendeley Desktop/Chen, Liu - 1997 - Statistical applications of the Poisson-Binomial and Conditional Bernoulli distributions.pdf:pdf},
issn = {10170405},
journal = {Statistica Sinica},
keywords = {case-control studies,conditional bernoulli distribution,erative weighted least squares,it-,logistic regression,poisson-binomial,pps sampling,survey sampling,weighted sampling},
pages = {875--892},
title = {{Statistical applications of the Poisson-Binomial and Conditional Bernoulli distributions}},
volume = {7},
year = {1997}
}
@article{Diakonikolas2015a,
abstract = {We give an algorithm for properly learning Poisson binomial distributions. A Poisson bino-mial distribution (PBD) of order n ∈ Z + is the discrete probability distribution of the sum of n mutually independent Bernoulli random variables. Given O(1/ǫ 2) samples from an unknown PBD P, our algorithm runs in time (1/ǫ) O(log log(1/ǫ)) , and outputs a hypothesis PBD that is ǫ-close to P in total variation distance. The sample complexity of our algorithm is known to be nearly-optimal, up to logarithmic factors, as established in previous work [DDS12]. How-ever, the previously best known running time for properly learning PBDs [DDS12, DKS15b] was (1/ǫ) O(log(1/ǫ)) , and was essentially obtained by enumeration over an appropriate ǫ-cover. We remark that the running time of this cover-based approach cannot be improved, as any ǫ-cover for the space of PBDs has size (1/ǫ) Ω(log(1/ǫ)) [DKS15b]. As one of our main contributions, we provide a novel structural characterization of PBDs, showing that any PBD P is ǫ-close to another PBD Q with O(log(1/ǫ)) distinct parame-ters. More precisely, we prove that, for all ǫ > 0, there exists an explicit collection M of (1/ǫ) O(log log(1/ǫ)) vectors of multiplicities, such that for any PBD P there exists a PBD Q with O(log(1/ǫ)) distinct parameters whose multiplicities are given by some element of M, such that Q is ǫ-close to P. Our proof combines tools from Fourier analysis and algebraic geometry. Our approach to the proper learning problem is as follows: Starting with an accurate non-proper hypothesis, we fit a PBD to this hypothesis. More specifically, we essentially start with the hypothesis computed by the computationally efficient non-proper learning algorithm in our recent work [DKS15b]. Our aforementioned structural characterization allows us to reduce the corresponding fitting problem to a collection of (1/ǫ) O(log log(1/ǫ)) systems of low-degree polynomial inequalities. We show that each such system can be solved in time (1/ǫ) O(log log(1/ǫ)) , which yields the overall running time of our algorithm.},
archivePrefix = {arXiv},
arxivId = {arXiv:1511.04066v1},
author = {Diakonikolas, Ilias and Kane, Daniel M and Stewart, Alistair},
eprint = {arXiv:1511.04066v1},
file = {:Users/cmueller/Documents/Mendeley Desktop/Diakonikolas, Kane, Stewart - 2015 - Properly Learning Poisson Binomial Distributions in Almost Polynomial Time.pdf:pdf},
keywords = {()},
title = {{Properly Learning Poisson Binomial Distributions in Almost Polynomial Time}},
year = {2015}
}
@article{Daskalakis2015b,
abstract = {We consider a basic problem in unsupervised learning: learning an unknown Poisson binomial distribution. A Poisson binomial distribution (PBD) over {\{}0,1,{\ldots},n{\}} is the distribution of a sum of {\$}{\$}n{\$}{\$}n independent Bernoulli random variables which may have arbitrary, potentially non-equal, expectations. These distributions were first studied by Poisson (Recherches sur la Probabilit{\`{e}} des jugements en mati{\'{e}} criminelle et en mati{\'{e}}re civile. Bachelier, Paris, 1837) and are a natural {\$}{\$}n{\$}{\$}n-parameter generalization of the familiar Binomial Distribution. Surprisingly, prior to our work this basic learning problem was poorly understood, and known results for it were far from optimal. We essentially settle the complexity of the learning problem for this basic class of distributions. As our first main result we give a highly efficient algorithm which learns to {\$}{\$}$\backslash$epsilon {\$}{\$}ϵ-accuracy (with respect to the total variation distance) using O{\~{}}(1/ϵ<sup>3</sup>) samples independent of{\$}{\$}n{\$}{\$}n. The running time of the algorithm is quasilinear in the size of its input data, i.e., O{\~{}}(log(n)/ϵ<sup>3</sup>) bit-operations (we write O{\~{}}(·) to hide factors which are polylogarithmic in the argument to O{\~{}}(·); thus, for example, O{\~{}}(alogb) denotes a quantity which is O(alogb·log<sup>c</sup>(alogb)) for some absolute constant c. Observe that each draw from the distribution is a log(n)-bit string). Our second main result is a proper learning algorithm that learns to ϵ-accuracy using O{\~{}}(1/ϵ<sup>2</sup>) samples, and runs in time (Formula Presented). This sample complexity is nearly optimal, since any algorithm for this problem must use $\Omega$(1/ϵ<sup>2</sup>) samples. We also give positive and negative results for some extensions of this learning problem to weighted sums of independent Bernoulli random variables.},
archivePrefix = {arXiv},
arxivId = {1107.2702},
author = {Daskalakis, Constantinos and Diakonikolas, Ilias and Servedio, Rocco A.},
doi = {10.1007/s00453-015-9971-3},
eprint = {1107.2702},
file = {:Users/cmueller/Documents/Mendeley Desktop/Daskalakis, Diakonikolas, Servedio - 2015 - Learning Poisson Binomial Distributions.pdf:pdf},
isbn = {9781450312455},
issn = {14320541},
journal = {Algorithmica},
keywords = {Density estimation,Learning,Poisson binomial distribution},
number = {1},
pages = {316--357},
title = {{Learning Poisson Binomial Distributions}},
volume = {72},
year = {2015}
}
@article{Zhao2012a,
author = {Zhao, Tuo and Roeder, Kathryn and Lafferty, John and Wasserman, Larry},
file = {:Users/cmueller/Documents/Mendeley Desktop/Zhao et al. - 2012 - The huge Package for High-dimensional Undirected Graph Estimation in R.pdf:pdf},
keywords = {graph estimation in r,huge package for high-dimensional,undirected},
pages = {1--12},
title = {{The huge Package for High-dimensional Undirected Graph Estimation in R}},
year = {2012}
}
@article{Kurtz2015a,
abstract = {16S ribosomal RNA (rRNA) gene and other environmental sequencing techniques provide snapshots of microbial communities, revealing phylogeny and the abundances of microbial populations across diverse ecosystems. While changes in microbial community structure are demonstrably associated with certain environmental conditions (from metabolic and immunological health in mammals to ecological stability in soils and oceans), identification of underlying mechanisms requires new statistical tools, as these datasets present several technical challenges. First, the abundances of microbial operational taxonomic units (OTUs) from amplicon-based datasets are compositional. Counts are normalized to the total number of counts in the sample. Thus, microbial abundances are not independent, and traditional statistical metrics (e.g., correlation) for the detection of OTU-OTU relationships can lead to spurious results. Secondly, microbial sequencing-based studies typically measure hundreds of OTUs on only tens to hundreds of samples; thus, inference of OTU-OTU association networks is severely under-powered, and additional information (or assumptions) are required for accurate inference. Here, we present SPIEC-EASI (SParse InversE Covariance Estimation for Ecological Association Inference), a statistical method for the inference of microbial ecological networks from amplicon sequencing datasets that addresses both of these issues. SPIEC-EASI combines data transformations developed for compositional data analysis with a graphical model inference framework that assumes the underlying ecological association network is sparse. To reconstruct the network, SPIEC-EASI relies on algorithms for sparse neighborhood and inverse covariance selection. To provide a synthetic benchmark in the absence of an experimentally validated gold-standard network, SPIEC-EASI is accompanied by a set of computational tools to generate OTU count data from a set of diverse underlying network topologies. SPIEC-EASI outperforms state-of-the-art methods to recover edges and network properties on synthetic data under a variety of scenarios. SPIEC-EASI also reproducibly predicts previously unknown microbial associations using data from the American Gut project.},
archivePrefix = {arXiv},
arxivId = {1408.4158},
author = {Kurtz, Zachary D and M{\"{u}}ller, Christian L and Miraldi, Emily R and Littman, Dan R and Blaser, Martin J and Bonneau, Richard A},
doi = {10.1371/journal.pcbi.1004226},
eprint = {1408.4158},
file = {:Users/cmueller/Documents/Mendeley Desktop/Kurtz et al. - 2015 - Sparse and Compositionally Robust Inference of Microbial Ecological Networks.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
number = {5},
pages = {e1004226},
pmid = {25950956},
title = {{Sparse and Compositionally Robust Inference of Microbial Ecological Networks.}},
url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004226},
volume = {11},
year = {2015}
}
@article{Caballe1996,
archivePrefix = {arXiv},
arxivId = {arXiv:1509.05326v1},
author = {Caballe, Adria and Bochkina, Natalia and Mayer, Claus},
eprint = {arXiv:1509.05326v1},
file = {:Users/cmueller/Documents/Mendeley Desktop/Caballe, Bochkina, Mayer - 1996 - Selection of the Regularization Parameter in Graph- ical Models using a Priori Knowledge of Network St.pdf:pdf},
keywords = {clustering,gene expres-,graphical lasso,high dimension,sion,sparse precision matrix},
title = {{Selection of the Regularization Parameter in Graph- ical Models using a Priori Knowledge of Network Struc- ture}},
year = {1996}
}
@article{Newman2003a,
abstract = {An increasing number of theoretical and empirical studies approach the function of the human brain from a network perspective. The analysis of brain networks is made feasible by the development of new imaging acquisition methods as well as new tools from graph theory and dynamical systems. This review surveys some of these methodological advances and summarizes recent findings on the architecture of structural and functional brain networks. Studies of the structural connectome reveal several modules or network communities that are interlinked by hub regions mediating communication processes between modules. Recent network analyses have shown that network hubs form a densely linked collective called a "rich club," centrally positioned for attracting and dispersing signal traffic. In parallel, recordings of resting and task-evoked neural activity have revealed distinct resting-state networks that contribute to functions in distinct cognitive domains. Network methods are increasingly applied in a clinical context, and their promise for elucidating neural substrates of brain and mental disorders is discussed. Abstract available from the publisher. Abstract available from the publisher.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0303516},
author = {Newman, M. E. J.},
doi = {10.1137/S003614450342480},
eprint = {0303516},
file = {:Users/cmueller/Documents/Mendeley Desktop/Newman - 2003 - The structure and function of complex networks(2).pdf:pdf},
isbn = {00361445},
issn = {1958-5969},
journal = {Dialogues in clinical neuroscience},
keywords = {Animals,Brain,Brain Mapping,Brain Mapping: methods,Brain: anatomy {\&} histology,Brain: physiology,Humans,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: physiology,Neural Pathways,Neural Pathways: anatomy {\&} histology,Neural Pathways: physiology,Neuroimaging,Neuroimaging: methods,Psychomotor Performance,Psychomotor Performance: physiology,Rest,Rest: physiology},
pages = {167--256},
pmid = {24174898},
primaryClass = {arXiv:cond-mat},
title = {{The structure and function of complex networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24876274},
volume = {45},
year = {2003}
}
@article{Buhlmann2014a,
abstract = {We review statistical methods for high-dimensional data analysis and pay particular attention to recent developments for assessing uncertainties in terms of controlling false positive statements (type I error) and p-values. The main focus is on regression models, but we also discuss graphical modeling and causal inference based on observational data. We illustrate the concepts and methods with various packages from the statistical software R using a high-throughput genomic data set about riboflavin production with Bacillus subtilis, which we make publicly available for the first time.},
author = {B{\"{u}}hlmann, Peter and Kalisch, Markus and Meier, Lukas},
doi = {10.1146/annurev-statistics-022513-115545},
file = {:Users/cmueller/Documents/Mendeley Desktop/B{\"{u}}hlmann, Kalisch, Meier - 2014 - High-dimensional statistics with a view toward applications in biology(2).pdf:pdf},
isbn = {2326-8298},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {causal inference,estimation,graphical modeling,multiple testing,penalized,regression},
number = {1},
pages = {255--278},
title = {{High-dimensional statistics with a view toward applications in biology}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-statistics-022513-115545},
volume = {1},
year = {2014}
}
@article{Ma,
author = {Ma, Jianzhu},
file = {:Users/cmueller/Documents/Mendeley Desktop/Ma - Unknown - Structure Learning Constrained by Node-Specific Degree Distribution.pdf:pdf},
title = {{Structure Learning Constrained by Node-Specific Degree Distribution}}
}
@article{Liu2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1006.3316v1},
author = {Liu, Han and Roeder, Kathryn and Wasserman, Larry},
eprint = {arXiv:1006.3316v1},
journal = {Proceedings of the Twenty-Third Annual Conference on Neural Information Processing Systems (NIPS)},
keywords = {Akaike information criterion,akaike,and phrases,bayesian information criterion,cross validation,information criterion,partial sparsistency,regularization selection,stability},
pages = {1--14},
title = {{Stability approach to regularization selection (stars) for high dimensional graphical models}},
url = {https://papers.nips.cc/paper/3966-stability-approach-to-regularization-selection-stars-for-high-dimensional-graphical-models.pdf},
year = {2010}
}
@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm--the graphical lasso--that is remarkably fast: It solves a 1000-node problem ( approximately 500,000 parameters) in at most a minute and is 30-4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and B{\"{u}}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
file = {:Users/cmueller/Documents/Mendeley Desktop/Friedman, Hastie, Tibshirani - 2008 - Sparse inverse covariance estimation with the graphical lasso(2).pdf:pdf},
institution = {Department of Statistics, Stanford University, CA 94305, USA.},
journal = {Biostatistics (Oxford, England)},
number = {3},
pages = {432--441},
title = {{Sparse inverse covariance estimation with the graphical lasso.}},
volume = {9},
year = {2008}
}
@article{Lederer2014,
author = {Lederer, Johannes C. and Mueller, Christian L.},
file = {:Users/cmueller/Documents/Mendeley Desktop/Lederer, Mueller - 2014 - Topology Adaptive Graph Estimation in High Dimensions.pdf:pdf},
journal = {Arxiv},
title = {{Topology Adaptive Graph Estimation in High Dimensions}},
year = {2014}
}
@article{Witten2011,
author = {Witten, Daniela M. and Friedman, Jerome H. and Simon, Noah},
doi = {10.1198/jcgs.2011.11051a},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {1,convex optimization,gene expression,inverse covariance estimation,networks,penalty,sparsity},
month = {jan},
number = {4},
pages = {892--900},
title = {{New Insights and Faster Computations for the Graphical Lasso}},
url = {http://www.tandfonline.com/doi/abs/10.1198/jcgs.2011.11051a},
volume = {20},
year = {2011}
}
@article{Ravikumar2011b,
author = {Ravikumar, Pradeep and Wainwright, Martin J. and Raskutti, Garvesh and Yu, Bin},
issn = {1935-7524},
journal = {Electronic Journal of Statistics},
number = {January 2010},
pages = {935--980},
title = {{High-dimensional covariance estimation by minimizing L1 -penalized log-determinant divergence}},
volume = {5},
year = {2011}
}
@article{Fiori2010,
author = {Fiori, Marcelo and Mus, Pablo and Sapiro, Guillermo},
file = {:Users/cmueller/Documents/Mendeley Desktop/Fiori, Mus, Sapiro - 2010 - Topology Constraints in Graphical Models.pdf:pdf},
pages = {1--9},
title = {{Topology Constraints in Graphical Models}},
year = {2010}
}
@article{Meinshausen:2010,
author = {Meinshausen, N and B{\"{u}}hlmann, P},
file = {:Users/cmueller/Documents/Mendeley Desktop/Meinshausen, B{\"{u}}hlmann - 2010 - Stability selection.pdf:pdf},
issn = {1467-9868},
journal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
keywords = {High dimensional data,Resampling,Stability selection,Structure estimation},
number = {4},
pages = {417--473},
publisher = {Blackwell Publishing Ltd},
title = {{Stability selection}},
volume = {72},
year = {2010}
}
@article{Lam2009a,
abstract = {This paper studies the sparsistency and rates of convergence for estimating sparse covariance and precision matrices based on penalized likelihood with nonconvex penalty functions. Here, sparsistency refers to the property that all parameters that are zero are actually estimated as zero with probability tending to one. Depending on the case of applications, sparsity priori may occur on the covariance matrix, its inverse or its Cholesky decomposition. We study these three sparsity exploration problems under a unified framework with a general penalty function. We show that the rates of convergence for these problems under the Frobenius norm are of order (s(n) log p(n)/n)(1/2), where s(n) is the number of nonzero elements, p(n) is the size of the covariance matrix and n is the sample size. This explicitly spells out the contribution of high-dimensionality is merely of a logarithmic factor. The conditions on the rate with which the tuning parameter $\lambda$(n) goes to 0 have been made explicit and compared under different penalties. As a result, for the L(1)-penalty, to guarantee the sparsistency and optimal rate of convergence, the number of nonzero elements should be small: sn'=O(pn) at most, among O(pn2) parameters, for estimating sparse covariance or correlation matrix, sparse precision or inverse correlation matrix or sparse Cholesky factor, where sn' is the number of the nonzero elements on the off-diagonal entries. On the other hand, using the SCAD or hard-thresholding penalty functions, there is no such a restriction.},
author = {Lam, Clifford and Fan, Jianqing},
doi = {10.1214/09-AOS720},
file = {:Users/cmueller/Documents/Mendeley Desktop/Lam, Fan - 2009 - Sparsistency and Rates of Convergence in Large Covariance Matrix Estimation.pdf:pdf},
issn = {0090-5364},
journal = {Annals of statistics},
month = {jan},
number = {6B},
pages = {4254--4278},
pmid = {21132082},
title = {{Sparsistency and Rates of Convergence in Large Covariance Matrix Estimation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2995610{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {37},
year = {2009}
}
@article{Hsieh2011,
abstract = {The ℓ1 regularized Gaussian maximum likelihood estimator has been shown to have strong statistical guarantees in recovering a sparse inverse covariance ma- trix, or alternatively the underlying graph structure of a Gaussian Markov Random Field, from very limited samples. We propose a novel algorithm for solving the resulting optimization problem which is a regularized log-determinant program. In contrast to other state-of-the-art methods that largely use first order gradient information, our algorithm is based on Newton’s method and employs a quadratic approximation, but with some modifications that leverage the structure of the sparse Gaussian MLE problem. We show that our method is superlinearly convergent, and also present experimental results using synthetic and real application data that demonstrate the considerable improvements in performance of our method when compared to other state-of-the-art methods.},
author = {Hsieh, Cho-Jui and Sustik, Matyas A. and Dhillon, Inderjit S. and Ravkiumar, Pradeep},
file = {:Users/cmueller/Documents/Mendeley Desktop/Hsieh et al. - 2011 - Sparse inverse covariance matrix estimation using quadratic approximation.pdf:pdf},
isbn = {9781618395993},
journal = {NIPS},
pages = {1--18},
title = {{Sparse inverse covariance matrix estimation using quadratic approximation}},
url = {http://www.cs.utexas.edu/users/inderjit/public{\_}papers/invcov{\_}nips11.pdf},
year = {2011}
}
@article{Tibshirani1996,
abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
author = {Tibshirani, Robert},
chapter = {267},
file = {:Users/cmueller/Documents/Mendeley Desktop/Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf:pdf},
institution = {Department of Statistics, University of Toronto},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {1},
pages = {267--288},
publisher = {JSTOR},
series = {B},
title = {{Regression shrinkage and selection via the lasso}},
url = {http://www.jstor.org/stable/2346178},
volume = {58},
year = {1996}
}
@article{Zhao2012,
abstract = {We describe an R package named huge which provides easy-to-use functions for estimating high dimensional undirected graphs from data. This package implements recent results in the literature, including Friedman et al. (2007), Liu et al. (2009, 2012) and Liu et al. (2010). Compared with the existing graph estimation package glasso, the huge package provides extra features: (1) instead of using Fortan, it is written in C, which makes the code more portable and easier to modify; (2) besides fitting Gaussian graphical models, it also provides functions for fitting high dimensional semiparametric Gaussian copula models; (3) more functions like data-dependent model selection, data generation and graph visualization; (4) a minor convergence problem of the graphical lasso algorithm is corrected; (5) the package allows the user to apply both lossless and lossy screening rules to scale up large-scale problems, making a tradeoff between computational and statistical efficiency.},
author = {Zhao, Tuo and Liu, H and Roeder, Kathryn},
file = {:Users/cmueller/Documents/Mendeley Desktop//Zhao, Liu, Roeder - 2012 - The huge package for high-dimensional undirected graph estimation in r.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {data-dependent model selection,estimation,glasso,high-dimensional undirected graph estimation,huge,lossless screening,lossy screening,semiparametric graph},
pages = {1059--1062},
title = {{The huge package for high-dimensional undirected graph estimation in r}},
url = {https://dl.acm.org/doi/10.5555/2503308.2343681},
volume = {13},
year = {2012}
}
@book{Lauritzen:1996,
author = {Lauritzen, Steffen L},
publisher = {Oxford University Press},
title = {{Graphical models}},
year = {1996}
}
@article{Wille:2004,
author = {Wille, Anja and Zimmermann, Philip and Vranov{\'{a}}, Eva and F{\"{u}}rholz, Andreas and Laule, Oliver and Bleuler, Stefan and Hennig, Lars and Others},
journal = {Genome Biol},
number = {11},
pages = {R92},
title = {{Sparse graphical Gaussian modeling of the isoprenoid gene network in Arabidopsis thaliana}},
volume = {5},
year = {2004}
}
@article{Meinshausen2006,
abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional inde- pendence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighbor- hood selection with the Lasso is a computationally attractive alter- native to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional indepen- dence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity compo- nents of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows like the number of observations raised to an arbitrary power.},
author = {Meinshausen, Nicolai and B{\"{u}}hlmann, Peter},
file = {:Users/cmueller/Documents/Mendeley Desktop//Meinshausen, B{\"{u}}hlmann - 2006 - High Dimensional Graphs and Variable Selection with the Lasso.pdf:pdf},
journal = {The Annals of Statistics},
number = {3},
pages = {1436--1462},
title = {{High Dimensional Graphs and Variable Selection with the Lasso}},
volume = {34},
year = {2006}
}
@article{Yuan:2007,
abstract = {We propose penalized likelihood methods for estimating the concentration matrix in the Gaussian graphical model. The methods lead to a sparse and shrinkage estimator of the concentration matrix that is positive definite, and thus conduct model selection and estimation simultaneously. The implementation of the methods is nontrivial because of the positive definite constraint on the concentration matrix, but we show that the computation can be done effectively by taking advantage of the efficient maxdet algorithm developed in convex optimization. We propose a BIC-type criterion for the selection of the tuning parameter in the penalized likelihood methods. The connection between our methods and existing methods is illustrated. Simulations and real examples demonstrate the competitive performance of the new methods.},
author = {Yuan, Ming and Lin, Yi},
doi = {10.1093/biomet/asm018},
journal = {Biometrika},
number = {1},
pages = {19--35},
title = {{Model selection and estimation in the Gaussian graphical model}},
url = {http://biomet.oxfordjournals.org/content/94/1/19.abstract},
volume = {94},
year = {2007}
}
@inproceedings{Liu:2011,
author = {Liu, Qiang and Ihler, Alexander T},
booktitle = {AISTATS},
file = {:Users/cmueller/Documents/Mendeley Desktop/Liu, Ihler - 2011 - Learning Scale Free Networks by Reweighted L1 regularization.pdf:pdf},
pages = {40--48},
title = {{Learning Scale Free Networks by Reweighted L1 regularization}},
year = {2011}
}
@article{Jones:2011,
abstract = {Motivation: The accurate prediction of residue-residue contacts, critical for maintaining the native fold of a protein, remains an open problem in the field of structural bioinformatics. Interest in this long-standing problem has increased recently with algorithmic improvements and the rapid growth in the sizes of sequence families. Progress could have major impacts in both structure and function prediction to name but two benefits. Sequence-based contact predictions are usually made by identifying correlated mutations within multiple sequence alignments (MSAs), most commonly through the information theoretic approach of calculating mutual information between pairs of sites in proteins. These predictions are often inaccurate because the true covariation signal in the MSA is often masked by biases from many ancillary indirect-coupling or phylogenetic effects. Here we present a novel method, PSICOV, which introduces the use of sparse inverse covariance estimation to the problem of protein contact prediction. Our method builds on work which had previously demonstrated corrections for phylogenetic and entropic correlation noise (Dunn et al., 2008) and allows accurate discrimination of direct from indirectly coupled mutation correlations in the MSA.Results: PSICOV displays a mean precision substantially better than the best performing normalised mutual information approach and Bayesian networks. For 118 out of 150 targets the L/5 (i.e. top- L/5 predictions for a protein of length L) precision for long-range contacts (sequence separation >23)was ≥0.5, which represents an improvement sufficient to be of significant benefit in protein structure prediction or model quality assessment.Availability: The PSICOV source code can be downloaded from http://bioinf.cs.ucl.ac.uk/downloads/PSICOVContact: d.jones@cs.ucl.ac.uk},
author = {Jones, David T and Buchan, Daniel W A and Cozzetto, Domenico and Pontil, Massimiliano},
doi = {10.1093/bioinformatics/btr638},
journal = {Bioinformatics},
title = {{PSICOV: Precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments}},
url = {http://bioinformatics.oxfordjournals.org/content/early/2011/11/17/bioinformatics.btr638.abstract},
year = {2011}
}
@article{Banerjee2008,
author = {Banerjee, Onureena and {El Ghaoui}, Laurent and D'Aspremont, Alexandre},
journal = {The Journal of Machine {\ldots}},
keywords = {binary data,convex optimization,gaussian,graphical model,maximum likelihood estimation,model selection},
pages = {485--516},
title = {{Model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data}},
url = {https://dl.acm.org/doi/10.5555/1390681.1390696},
volume = {9},
year = {2008}
}
@article{Przulj2007,
abstract = {MOTIVATION: Analogous to biological sequence comparison, comparing cellular networks is an important problem that could provide insight into biological understanding and therapeutics. For technical reasons, comparing large networks is computationally infeasible, and thus heuristics, such as the degree distribution, clustering coefficient, diameter, and relative graphlet frequency distribution have been sought. It is easy to demonstrate that two networks are different by simply showing a short list of properties in which they differ. It is much harder to show that two networks are similar, as it requires demonstrating their similarity in all of their exponentially many properties. Clearly, it is computationally prohibitive to analyze all network properties, but the larger the number of constraints we impose in determining network similarity, the more likely it is that the networks will truly be similar.

RESULTS: We introduce a new systematic measure of a network's local structure that imposes a large number of similarity constraints on networks being compared. In particular, we generalize the degree distribution, which measures the number of nodes 'touching' k edges, into distributions measuring the number of nodes 'touching' k graphlets, where graphlets are small connected non-isomorphic subgraphs of a large network. Our new measure of network local structure consists of 73 graphlet degree distributions of graphlets with 2-5 nodes, but it is easily extendible to a greater number of constraints (i.e. graphlets), if necessary, and the extensions are limited only by the available CPU. Furthermore, we show a way to combine the 73 graphlet degree distributions into a network 'agreement' measure which is a number between 0 and 1, where 1 means that networks have identical distributions and 0 means that they are far apart. Based on this new network agreement measure, we show that almost all of the 14 eukaryotic PPI networks, including human, resulting from various high-throughput experimental techniques, as well as from curated databases, are better modeled by geometric random graphs than by Erd{\"{o}}s-R{\'{e}}ny, random scale-free, or Barab{\'{a}}si-Albert scale-free networks.

AVAILABILITY: Software executables are available upon request.},
author = {Przulj, Natasa},
doi = {10.1093/bioinformatics/btl301},
file = {:Users/cmueller/Documents/Mendeley Desktop/Przulj - 2007 - Biological network comparison using graphlet degree distribution.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Computer Graphics,Computer Simulation,Models, Biological,Proteome,Proteome: metabolism,Signal Transduction,Signal Transduction: physiology,User-Computer Interface},
month = {jan},
number = {2},
pages = {e177--83},
pmid = {17237089},
title = {{Biological network comparison using graphlet degree distribution.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17237089},
volume = {23},
year = {2007}
}
@article{Hayes2013,
abstract = {MOTIVATION: Large amounts of biological network data exist for many species. Analogous to sequence comparison, network comparison aims to provide biological insight. Graphlet-based methods are proving to be useful in this respect. Recently some doubt has arisen concerning the applicability of graphlet-based measures to low edge density networks-in particular that the methods are 'unstable'-and further that no existing network model matches the structure found in real biological networks.

RESULTS: We demonstrate that it is the model networks themselves that are 'unstable' at low edge density and that graphlet-based measures correctly reflect this instability. Furthermore, while model network topology is unstable at low edge density, biological network topology is stable. In particular, one must distinguish between average density and local density. While model networks of low average edge densities also have low local edge density, that is not the case with protein-protein interaction (PPI) networks: real PPI networks have low average edge density, but high local edge densities, and hence, they (and thus graphlet-based measures) are stable on these networks. Finally, we use a recently devised non-parametric statistical test to demonstrate that PPI networks of many species are well-fit by several models not previously tested. In addition, we model several viral PPI networks for the first time and demonstrate an exceptionally good fit between the data and theoretical models.},
author = {Hayes, Wayne and Sun, Kai and Pr{\v{z}}ulj, Nata{\v{s}}a},
doi = {10.1093/bioinformatics/bts729},
file = {:Users/cmueller/Documents/Mendeley Desktop/Hayes, Sun, Pr{\v{z}}ulj - 2013 - Graphlet-based measures are suitable for biological network comparison.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Models, Biological,Protein Interaction Mapping,Protein Interaction Mapping: methods,Protein Interaction Maps,Statistics, Nonparametric,Viral Proteins,Viral Proteins: metabolism},
month = {feb},
number = {4},
pages = {483--91},
pmid = {23349212},
title = {{Graphlet-based measures are suitable for biological network comparison.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23349212},
volume = {29},
year = {2013}
}
@article{Hocevar2014,
abstract = {MOTIVATION: Small-induced subgraphs called graphlets are emerging as a possible tool for exploration of global and local structure of networks and for analysis of roles of individual nodes. One of the obstacles to their wider use is the computational complexity of algorithms for their discovery and counting.

RESULTS: We propose a new combinatorial method for counting graphlets and orbit signatures of network nodes. The algorithm builds a system of equations that connect counts of orbits from graphlets with up to five nodes, which allows to compute all orbit counts by enumerating just a single one. This reduces its practical time complexity in sparse graphs by an order of magnitude as compared with the existing pure enumeration-based algorithms.

AVAILABILITY AND IMPLEMENTATION: Source code is available freely at http://www.biolab.si/supp/orca/orca.html.},
author = {Ho{\v{c}}evar, Toma{\v{z}} and Dem{\v{s}}ar, Janez},
doi = {10.1093/bioinformatics/btt717},
file = {:Users/cmueller/Documents/Mendeley Desktop/Ho{\v{c}}evar, Dem{\v{s}}ar - 2014 - A combinatorial approach to graphlet counting.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Computer Graphics,Computer Simulation,Data Interpretation, Statistical,Humans,Models, Biological,Protein Interaction Mapping,Protein Interaction Mapping: methods,Proteins,Proteins: metabolism},
month = {feb},
number = {4},
pages = {559--65},
pmid = {24336411},
title = {{A combinatorial approach to graphlet counting.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24336411},
volume = {30},
year = {2014}
}
@article{Yaveroglu2014,
abstract = {Sophisticated methods for analysing complex networks promise to be of great benefit to almost all scientific disciplines, yet they elude us. In this work, we make fundamental methodological advances to rectify this. We discover that the interaction between a small number of roles, played by nodes in a network, can characterize a network's structure and also provide a clear real-world interpretation. Given this insight, we develop a framework for analysing and comparing networks, which outperforms all existing ones. We demonstrate its strength by uncovering novel relationships between seemingly unrelated networks, such as Facebook, metabolic, and protein structure networks. We also use it to track the dynamics of the world trade network, showing that a country's role of a broker between non-trading countries indicates economic prosperity, whereas peripheral roles are associated with poverty. This result, though intuitive, has escaped all existing frameworks. Finally, our approach translates network topology into everyday language, bringing network analysis closer to domain scientists.},
author = {Yaveroglu, {\"{O}}mer Nebil and Malod-Dognin, No{\"{e}}l and Davis, Darren and Levnajic, Zoran and Janjic, Vuk and Karapandza, Rasa and Stojmirovic, Aleksandar and Pr{\v{z}}ulj, Nata{\v{s}}a},
doi = {10.1038/srep04547},
file = {:Users/cmueller/Documents/Mendeley Desktop/Yaveroğlu et al. - 2014 - Revealing the hidden language of complex networks.pdf:pdf},
issn = {2045-2322},
journal = {Scientific reports},
month = {jan},
pages = {4547},
pmid = {24686408},
title = {{Revealing the hidden language of complex networks.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3971399{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2014}
}

@article{Foygel2010,
abstract = {Gaussian graphical models with sparsity in the inverse covariance matrix are of significant interest in many modern applications. For the problem of recovering the graphical structure, information criteria provide useful optimization objectives for algorithms searching through sets of graphs or for selection of tuning parameters of other methods such as the graphical lasso, which is a likelihood penalization technique. In this paper we establish the consistency of an extended Bayesian information criterion for Gaussian graphical models in a scenario where both the number of variables p and the sample size n grow. Compared to earlier work on the regression case, our treatment allows for growth in the number of non-zero parameters in the true model, which is necessary in order to cover connected graphs. We demonstrate the performance of this criterion on simulated data when used in conjunction with the graphical lasso, and verify that the criterion indeed performs better than either cross-validation or the ordinary Bayesian information criterion when p and the number of non-zero parameters q both scale with n.},
archivePrefix = {arXiv},
arxivId = {1011.6640},
author = {Foygel, Rina and Drton, Mathias},
eprint = {1011.6640},
file = {:Users/cmueller/Documents/Mendeley Desktop/Foygel, Drton - 2010 - Extended Bayesian Information Criteria for Gaussian Graphical Models.pdf:pdf},
isbn = {9781617823800},
journal = {Arxiv preprint},
mendeley-groups = {PULSAR},
pages = {1--14},
title = {{Extended Bayesian Information Criteria for Gaussian Graphical Models}},
url = {https://arxiv.org/abs/1011.6640},
year = {2010}
}
@article{Lafferty2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1201.0794v2},
author = {Lafferty, John and Liu, Han and Wasserman, Larry},
doi = {10.1214/12-STS391},
eprint = {arXiv:1201.0794v2},
file = {:Users/cmueller/Documents/Mendeley Desktop/Lafferty, Liu, Wasserman - 2012 - Sparse Nonparametric Graphical Models.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,gaussian copula,high-dimensional inference,kernel density estimation,oracle inequal-,undirected graphical model},
mendeley-groups = {PULSAR},
month = {nov},
number = {4},
pages = {519--537},
title = {{Sparse Nonparametric Graphical Models}},
url = {http://projecteuclid.org/euclid.ss/1356098554},
volume = {27},
year = {2012}
}

@article{Ravikumar:2010,
author = {Ravikumar, Pradeep and Wainwright, Martin J and Lafferty, John D and Others},
journal = {The Annals of Statistics},
mendeley-groups = {PULSAR},
number = {3},
pages = {1287--1319},
publisher = {Institute of Mathematical Statistics},
title = {{High-dimensional Ising model selection using L1-regularized logistic regression}},
volume = {38},
year = {2010}
}

@inproceedings{Tandon2014,
author = {Tandon, Rashish and Ravikumar, Pradeep},
booktitle = {Proceedings of The 31st International Conference on Machine Learning},
file = {:Users/cmueller/Documents/Mendeley Desktop/Tandon, Ravikumar - 2014 - Learning Graphs with a Few Hubs.pdf:pdf},
pages = {602--610},
title = {{Learning Graphs with a Few Hubs}},
url = {https://proceedings.mlr.press/v32/tandon14.html},
year = {2014}
}

@article{Hocevar2016,
abstract = {Graphlet analysis is an approach to network analysis that is particularly popular in bioinformatics. We show how to set up a system of linear equations that relate the orbit counts and can be used in an algorithm that is significantly faster than the existing approaches based on direct enumeration of graphlets. The algorithm requires existence of a vertex with certain properties; we show that such vertex exists for graphlets of arbitrary size, except for complete graphs and {\$}C{\_}4{\$}, which are treated separately. Empirical analysis of running time agrees with the theoretical results.},
archivePrefix = {arXiv},
arxivId = {1601.06834},
author = {Ho{\v{c}}evar, Toma{\v{z}} and Dem{\v{s}}ar, Janez},
eprint = {1601.06834},
file = {:Users/cmueller/Documents/Mendeley Desktop/Ho{\v{c}}evar, Dem{\v{s}}ar - 2016 - Combinatorial algorithm for counting small induced graphs and orbits.pdf:pdf},
journal = {arXiv 1601.06834},
pages = {1--15},
title = {{Combinatorial algorithm for counting small induced graphs and orbits}},
url = {https://arxiv.org/abs/1601.06834},
year = {2016}
}
@article{Hsieh2014,
abstract = {The `1-regularized Gaussian maximum likelihood estimator (MLE) has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix, or alternatively the underlying graph structure of a Gaussian Markov Random Field, from very limited samples. We propose a novel algorithm for solving the resulting optimization problem which is a regularized log-determinant program. In contrast to recent state-of-the-art methods that largely use rst order gradient information, our algorithm is based on Newton's method and employs a quadratic approximation, but with some modi cations that leverage the structure of the sparse Gaussian MLE problem. We show that our method is superlinearly convergent, and present experimental results using synthetic and real-world application data that demonstrate the considerable improvements in performance of our method when compared to previous methods.},
author = {Hsieh, Cho-Jui and Sustik, M{\'{a}}ty{\'{a}}s A and Dhillon, Inderjit S and Ravikumar, Pradeep},
file = {:Users/cmueller/Documents/Mendeley Desktop//Hsieh et al. - 2014 - QUIC Quadratic Approximation for Sparse Inverse Covariance Estimation.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Gaussian Markov,covariance,graphical model,optimization,random field,regularization},
pages = {2911--2947},
title = {{QUIC: Quadratic Approximation for Sparse Inverse Covariance Estimation}},
url = {https://jmlr.org/papers/v15/hsieh14a.html},
volume = {15},
year = {2014}
}
@article{Shah2013,
abstract = {Stability Selection was recently introduced by Meinshausen and Buhlmann (2010) as a very general technique designed to improve the performance of a variable selection algorithm. It is based on aggregating the results of applying a selection procedure to subsamples of the data. We introduce a variant, called Complementary Pairs Stability Selection (CPSS), and derive bounds both on the expected number of variables included by CPSS that have low selection probability under the original procedure, and on the expected number of high selection probability variables that are excluded. These results require no (e.g. exchangeability) assumptions on the underlying model or on the quality of the original selection procedure. Under reasonable shape restrictions, the bounds can be further tightened, yielding improved error control, and therefore increasing the applicability of the methodology.},
archivePrefix = {arXiv},
arxivId = {1105.5578},
author = {Shah, Rajen D. and Samworth, Richard J.},
doi = {10.1111/j.1467-9868.2011.01034.x},
eprint = {1105.5578},
file = {:Users/cmueller/Documents/Mendeley Desktop/Shah, Samworth - 2013 - Variable selection with error control Another look at stability selection.pdf:pdf},
isbn = {1369-7412},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Complementary pairs stability selection,R-concavity,Subagging,Subsampling,Variable selection},
mendeley-groups = {PULSAR},
pages = {55--80},
title = {{Variable selection with error control: Another look at stability selection}},
volume = {75},
year = {2013}
}
@article{Lim2013c,
abstract = {Cross-validation (CV) is often used to select the regularization parameter in high dimensional problems. However, when applied to the sparse modeling method Lasso, CV leads to models that are unstable in high-dimensions, and consequently not suited for reliable interpretation. In this paper, we propose a model-free criterion ESCV based on a new estimation stability (ES) metric and CV. Our proposed ESCV finds a locally ES-optimal model smaller than the CV choice so that the it fits the data and also enjoys estimation stability property. We demonstrate that ESCV is an effective alternative to CV at a similar easily parallelizable computational cost. In particular, we compare the two approaches with respect to several performance measures when applied to the Lasso on both simulated and real data sets. For dependent predictors common in practice, our main finding is that, ESCV cuts down false positive rates often by a large margin, while sacrificing little of true positive rates. ESCV usually outperforms CV in terms of parameter estimation while giving similar performance as CV in terms of prediction. For the two real data sets from neuroscience and cell biology, the models found by ESCV are less than half of the model sizes by CV. Judged based on subject knowledge, they are more plausible than those by CV as well. We also discuss some regularization parameter alignment issues that come up in both approaches.},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.3128v1},
author = {Lim, Chinghway and Yu, Bin},
doi = {10.1080/10618600.2015.1020159},
eprint = {arXiv:1303.3128v1},
file = {:Users/cmueller/Documents/Mendeley Desktop/Lim, Yu - 2013 - Estimation Stability with Cross Validation (ESCV)(2).pdf:pdf},
issn = {1061-8600},
journal = {arXiv preprint arXiv:1303.3128},
keywords = {lasso,model selection,parameter estimation,prediction},
pages = {1--31},
title = {{Estimation Stability with Cross Validation (ESCV)}},
url = {https://arxiv.org/abs/1303.3128},
year = {2013}
}
@article{Poisson1837,
author = {Poisson, Simon D.},
title = {Recherches sur la probabilite des jugements en matiere criminelle et en matire civile},
publisher = {Bachelier, Paris},
year = {1837}
}
@book{Boyd2003,
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Boyd, S and Vandenberge, L},
doi = {10.1109/TAC.2006.884922},
eprint = {1111.6189v1},
file = {:Users/cmueller/Documents/Mendeley Desktop/Boyd, Vandenberge - 2003 - Convex Optimization.pdf:pdf},
isbn = {9780521833783},
issn = {0018-9286},
pmid = {20876008},
title = {{Convex Optimization}},
year = {2003}
}
@article{Kuchaiev2010,
abstract = {Sequence comparison and alignment has had an enormous impact on our understanding of evolution, biology and disease. Comparison and alignment of biological networks will probably have a similar impact. Existing network alignments use information external to the networks, such as sequence, because no good algorithm for purely topological alignment has yet been devised. In this paper, we present a novel algorithm based solely on network topology, that can be used to align any two networks. We apply it to biological networks to produce by far the most complete topological alignments of biological networks to date. We demonstrate that both species phylogeny and detailed biological function of individual proteins can be extracted from our alignments. Topology-based alignments have the potential to provide a completely new, independent source of phylogenetic information. Our alignment of the protein-protein interaction networks of two very different species-yeast and human-indicate that even distant species share a surprising amount of network topology, suggesting broad similarities in internal cellular wiring across all life on Earth.},
archivePrefix = {arXiv},
arxivId = {0810.3280},
author = {Kuchaiev, Oleksii and Milenkovic, Tijana and Memisevic, Vesna and Hayes, Wayne and Przulj, Natasa},
doi = {10.1098/rsif.2010.0063},
eprint = {0810.3280},
file = {:Users/cmueller/Documents/Mendeley Desktop/Kuchaiev et al. - 2010 - Topological network alignment uncovers biological function and phylogeny.pdf:pdf},
isbn = {1742-5662},
issn = {1742-5662},
journal = {Journal of the Royal Society, Interface / the Royal Society},
keywords = {Algorithms,Computational Biology,Humans,Models, Biological,Phylogeny,Proteins,Proteins: chemistry,Proteins: genetics,Proteins: metabolism,Saccharomyces cerevisiae,Saccharomyces cerevisiae Proteins,Saccharomyces cerevisiae Proteins: chemistry,Saccharomyces cerevisiae Proteins: genetics,Saccharomyces cerevisiae Proteins: metabolism,Saccharomyces cerevisiae: genetics,Saccharomyces cerevisiae: metabolism},
number = {50},
pages = {1341--54},
pmid = {20236959},
title = {{Topological network alignment uncovers biological function and phylogeny.}},
url = {http://rsif.royalsocietypublishing.org/content/early/2010/03/24/rsif.2010.0063},
volume = {7},
year = {2010}
}

@inproceedings{Kondor2009,
address = {New York, NY, USA},
author = {Kondor, Risi and Shervashidze, Nino and Borgwardt, Karsten M},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
doi = {10.1145/1553374.1553443},
file = {:Users/cmueller/Documents/Mendeley Desktop/Kondor, Shervashidze, Borgwardt - 2009 - The Graphlet Spectrum.pdf:pdf},
isbn = {978-1-60558-516-1},
number = {1},
pages = {529--536},
publisher = {ACM},
series = {ICML '09},
title = {{The Graphlet Spectrum}},
url = {http://doi.acm.org/10.1145/1553374.1553443},
year = {2009}
}
@article{Shervashidze2009,
abstract = {State-of-the-art graph kernels do not scale to large graphs with hundreds of nodes and thousands of edges. In this article we propose to compare graphs by counting common {\{}$\backslash$it graphlets{\}}, $\backslash$ie subgraphs with {\$}k{\$} nodes where {\$}k \backslashin \backslash{\{} 3, 4, 5 \backslash{\}}{\$}. Exhaustive enumeration of all graphlets being prohibitively expensive, we introduce two theoretically grounded speedup schemes, one based on sampling and the second one specifically designed for bounded degree graphs. In our experimental evaluation, our novel kernels allow us to efficiently compare large graphs that cannot be tackled by existing graph kernels.},
author = {Shervashidze, Nino and Vishwanathan, S V N and Petri, Tobias H and Mehlhorn, Kurt and Borgwardt, Karsten and Petri, Tobias H},
file = {:Users/cmueller/Documents/Mendeley Desktop//Shervashidze et al. - 2009 - Efficient graphlet kernels for large graph comparison.pdf:pdf},
journal = {International conference on artificial intelligence and statistics},
keywords = {,Learning/Statistics {\&} Optimisation},
pages = {488--495},
title = {{Efficient graphlet kernels for large graph comparison}},
url = {http://eprints.pascal-network.org/archive/00004965/},
volume = {5},
year = {2009}
}
@article{Przulj2004,
abstract = {MOTIVATION: Networks have been used to model many real-world phenomena to better understand the phenomena and to guide experiments in order to predict their behavior. Since incorrect models lead to incorrect predictions, it is vital to have as accurate a model as possible. As a result, new techniques and models for analyzing and modeling real-world networks have recently been introduced. RESULTS: One example of large and complex networks involves protein-protein interaction (PPI) networks. We analyze PPI networks of yeast Saccharomyces cerevisiae and fruitfly Drosophila melanogaster using a newly introduced measure of local network structure as well as the standardly used measures of global network structure. We examine the fit of four different network models, including Erdos-Renyi, scale-free and geometric random network models, to these PPI networks with respect to the measures of local and global network structure. We demonstrate that the currently accepted scale-free model of PPI networks fails to fit the data in several respects and show that a random geometric model provides a much more accurate model of the PPI data. We hypothesize that only the noise in these networks is scale-free. Conclusions: We systematically evaluate how well-different network models fit the PPI networks. We show that the structure of PPI networks is better modeled by a geometric random graph than by a scale-free model. SUPPLEMENTARY INFORMATION: Supplementary information is available at http://www.cs.utoronto.ca/{\~{}}juris/data/data/ppiGRG04/},
archivePrefix = {arXiv},
arxivId = {q-bio/0404017},
author = {Pr{\v{z}}ulj, N. and Corneil, D. G. and Jurisica, I.},
doi = {10.1093/bioinformatics/bth436},
eprint = {0404017},
file = {:Users/cmueller/Documents/Mendeley Desktop/Pr{\v{z}}ulj, Corneil, Jurisica - 2004 - Modeling interactome Scale-free or geometric.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {18},
pages = {3508--3515},
pmid = {15284103},
primaryClass = {q-bio},
title = {{Modeling interactome: Scale-free or geometric?}},
volume = {20},
year = {2004}
}
@article{Guerrero2008,
abstract = {Quantitative analysis of tandem-affinity purified cross-linked (x) protein complexes (QTAX) is a powerful technique for the identification of protein interactions, including weak and/or transient components. Here, we apply a QTAX-based tag-team mass spectrometry strategy coupled with protein network analysis to acquire a comprehensive and detailed assessment of the protein interaction network of the yeast 26S proteasome. We have determined that the proteasome network is composed of at least 471 proteins, significantly more than the total number of proteins identified by previous reports using proteasome subunits as baits. Validation of the selected proteasome-interacting proteins by reverse copurification and immunoblotting experiments with and without cross-linking, further demonstrates the power of the QTAX strategy for capturing protein interactions of all natures. In addition, {\textgreater}80{\%} of the identified interactions have been confirmed by existing data using protein network analysis. Moreover, evidence obtained through network analysis links the proteasome to protein complexes associated with diverse cellular functions. This work presents the most complete analysis of the proteasome interaction network to date, providing an inclusive set of physical interaction data consistent with physiological roles for the proteasome that have been suggested primarily through genetic analyses. Moreover, the methodology described here is a general proteomic tool for the comprehensive study of protein interaction networks.},
author = {Guerrero, Cortnie and Milenkovic, Tijana and Przulj, Natasa and Kaiser, Peter and Huang, Lan},
doi = {10.1073/pnas.0801870105},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {PNAS},
keywords = {Mass Spectrometry,Proteasome Endopeptidase Complex/*metabolism,Protein Binding,Protein Interaction Mapping,Proteins/chemistry/isolation {\&} purification/*metab,Saccharomyces cerevisiae/metabolism},
number = {36},
pages = {13333--13338},
pmid = {18757749},
title = {{Characterization of the proteasome interaction network using a QTAX-based tag-team strategy and protein interaction network analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18757749},
volume = {105},
year = {2008}
}

@article{Ramanan2016,
abstract = {Increasing incidence of inflammatory bowel diseases such as Crohn's disease (CD) in developed nations is associated with changes to the environment, such as decreased prevalence of helminth colonization and alterations to the gut microbiota. We find that helminth infection protects mice deficient in the CD susceptibility geneNod2from intestinal abnormalities by inhibiting colonization with an inflammatoryBacteroidesspecies. Colonization resistance toBacteroideswas dependent on type-2 immunity, which promoted the establishment of a protective microbiota enriched in Clostridiales. Additionally, we show that individuals from helminth-endemic regions harbor a similar protective microbiota, and that deworming treatment reduced Clostridiales and increased Bacteroidales. These results support a model of the hygiene hypothesis whereby certain individuals are genetically susceptible to the consequences of a changing microbial environment.},
author = {Ramanan, Deepshika and Bowcutt, Rowann and Lee, Soo Ching and Tang, Mei San and Kurtz, Zachary D and Ding, Yi and Honda, Kenya and Gause, William C and Blaser, Martin J and Bonneau, Richard A and Lim, Yvonne Al and Loke, P'ng and Cadwell, Ken},
doi = {10.1126/science.aaf3229},
issn = {1095-9203},
journal = {Science},
language = {en},
month = {apr},
number = {6285},
pages = {608--612},
pmid = {27080105},
publisher = {American Association for the Advancement of Science},
title = {{Helminth infection promotes colonization resistance via type 2 immunity.}},
url = {http://science.sciencemag.org/content/352/6285/608.abstract},
volume = {352},
year = {2016}
}

@misc{Mueller:2016,
Author = {Christian L. Müller and Richard Bonneau and Zachary Kurtz},
Title = {Generalized Stability Approach for Regularized Graphical Models},
Year = {2016},
Eprint = {arXiv:1605.07072},
}


@misc{Caballe:2015,
Author = {Adria Caballe and Natalia Bochkina and Claus Mayer},
Title = {Selection of the Regularization Parameter in Graphical Models using Network Characteristics},
Year = {2015},
Eprint = {arXiv:1509.05326},
}
